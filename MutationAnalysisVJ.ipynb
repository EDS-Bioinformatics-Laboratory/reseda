{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allinfo_file = \"final/B001-B_S83_L001.assembled-ATGCATGC-IGH_HUMAN-all_info.csv\"\n",
    "v_file = \"B001-B_S83_L001.assembled-ATGCATGC-IGHV_human-e-clean.sam.mut.txt\"\n",
    "j_file = \"B001-B_S83_L001.assembled-ATGCATGC-IGHJ_human-e-clean.sam.mut.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile = allinfo_file.replace(\"-all_info.csv\", \"-clones-mut-sites.csv\")\n",
    "print(outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allinfo = pd.read_csv(allinfo_file, sep='\\t')\n",
    "#print(\"allinfo entries:\", len(allinfo))\n",
    "#allinfo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if acc in allinfo is unique. ANSWER: no\n",
    "#allinfo['acc'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check properties of accs in allinfo that are not unique\n",
    "#count_acc_allinfo = allinfo.groupby('acc').agg(['nunique'])\n",
    "#col = 'V_sub'\n",
    "#count_acc_allinfo.sort_values((col,'nunique'), ascending=False)[col].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 'None' with 0 for the nr_sites column\n",
    "allinfo['nr_sites'] = allinfo['nr_sites'].replace('None', 0).apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = pd.read_csv(v_file, sep=' ')\n",
    "#print(\"v entries:\", len(v))\n",
    "#v.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if acc in v is unique. ANSWER: nope\n",
    "#v['acc'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = pd.read_csv(j_file, sep=' ')\n",
    "#print(\"j entries:\", len(j))\n",
    "#j.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if acc in j is unique. ANSWER: nope\n",
    "#j['acc'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up the gene names\n",
    "clean_name = lambda x: x.split(\"|\")[1]\n",
    "v['gene'] = [g for g in map(clean_name, v['gene'])]\n",
    "j['gene'] = [g for g in map(clean_name, j['gene'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(allinfo, v, how='left', left_on=['acc','V_gene'], right_on=['acc','gene'])\n",
    "df = pd.merge(df, j, how='left', left_on=['acc','J_gene'], right_on=['acc','gene'])\n",
    "#print(\"df merged enties:\", len(df))\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[(df['cdr3_qual_min'] >= 30) & (df['V_sub'] != 'None') & (df['J_sub'] != 'None') & ((df['V_flag'] == '0') | (df['V_flag'] == '16')) & ((df['J_flag'] == '0') | (df['J_flag'] == '16'))]\n",
    "#print(\"df filtered entries:\", len(df))\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove entries where the V and J alignments overlap each other\n",
    "df = df.drop(df.loc[(df['start.pos_y']>df['start.pos_x']) & (df['start.pos_y']<df['end.pos_x']) | (df['end.pos_y']>df['start.pos_x']) & (df['end.pos_y']<df['end.pos_x'])].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the alignment with the longest alignment length (V gene)\n",
    "longest_alignment = df.groupby('acc').agg({'align.length_x': max})\n",
    "longest_alignment = longest_alignment.reset_index()\n",
    "#longest_alignment.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df, longest_alignment, how='inner', left_on=['acc','align.length_x'], right_on=['acc','align.length_x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acc in df unique?\n",
    "#print('Entries:', len(df))\n",
    "#print('Unique:', df['acc'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check why accessions are not unique\n",
    "#tmp = df.groupby('acc').agg('nunique')\n",
    "#tmp.apply(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort on nr of different cigar strings (descending)\n",
    "#tmp = tmp.sort_values('cigar_y', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show first entry for inspection\n",
    "#df.loc[df['acc']==tmp.index[0],['start.pos_x','end.pos_x','cigar_y','start.pos_y','end.pos_y','mut.count_y','align.length_y','align.seq_y']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group data per clone (CDR3pep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clones = df.groupby(['cdr3pep','V_sub','J_sub']).agg({'acc': 'nunique', 'beforeMID': 'nunique', 'mut.count_x': [sum, np.mean], 'mut.frac_x': [sum, np.mean], 'mut.count_y': [sum, np.mean], 'mut.frac_y': [sum, np.mean], 'nr_sites': [sum, np.mean]})\n",
    "clones = clones.sort_values(by=('acc','nunique'), ascending=False)\n",
    "#print(\"Clones entries:\", len(clones))\n",
    "#clones.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clones.columns = ['.'.join(col).strip() for col in clones.columns.values]\n",
    "#clones.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clones.to_csv(outfile, sep='\\t')\n",
    "print(\"Wrote\", outfile, \"to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
